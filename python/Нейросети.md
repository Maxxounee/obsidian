# Градиентный спуск

[Статья про batch, эпохи и градиентные спуски](https://neurohive.io/ru/osnovy-data-science/jepoha-razmer-batcha-iteracija/)


_Градиентный спуск - алгоритм итеративной оптимизации, используемый в машинном обучении для получения более точного результата ( то есть поиск минимума кривой или многомерной поверхности_

_Градиент_ показывает скорость убывания или возрастания функции

_Спуск_ говорит о том, что мы имеем дело с убыванием


# Функция потерь

_Функция потерь - это ключевой компонент обучения нейронных сетей и других алгоритмов машинного обучения. Она количественно оценивает, насколько предсказания модели отличаются от истинниых значений. Цель оптимизации - минимизировать эту функцию._

## Зачем нужна функция потерь?

* Измеряет ошибку модели на каждом шаге обучения
* Направляет оптимизатор (например, SGD, Adam) в процессе градиентного спуска
* Определяет качество модели: чем меньше значение loss, тем лучше модель предсказывает
